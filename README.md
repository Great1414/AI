# AI

## 电影推荐模型 ##

*数据来源*

http://www.grouplens.org/datasets/movielens/

*数据格式*

#### ratings.dat ####

UserID::MovieID::Rating::Timestamp

#### users.dat ####
UserID::Gender::Age::Occupation::Zip-code

#### movies.dat ####
MovieID::Title::Genres

#### personalMoviesRatings.dat ####
UserID::MovieID::Rating::Timestamp

## 构建分类模型 ##

* 常见分类模型 *

线性模型、决策树、朴素贝叶斯

线性模型：

1.逻辑回归：概率模型，预测摸个数据点属于正类的概率估计

2.支持向量机：对等连接函数估计值大于或等于阈值0时，标记1 否则标记0（阈值为自适应模型参数）

朴素贝叶斯：

概率模型，假设各个特征之间条件独立，属于某个类别的概率->若干个概率之积（特征在给定某个类别下出现的条件概率和该类别的先验概率，这些概率都可以通过数据的频率估计得到）

分类过程：就是在给定特征和类别概率的情况下选择最可能的类别

决策树：

非概率模型，表达复杂的非线性模式和特征相互关系，处理类属和数值特征，不需要输入股数据归一或标准化，适用集成方法，形成决策森林

每一个特征的决策通过评估特征分裂的信息增益，最后选择分割数据集最优的特征

评估方法：基尼不纯和熵值

* 模型参数的调优

1. 线性模型： 逻辑回归和SVM有着相同的参数，由于都是使用SGD优化方案，不同在于两者的损失函数不同

(1) 迭代

(2) 步长: 较大的步长收敛较快，但可能导致局部最优解

(3) 正规化：通过限制模型的复杂度避免模型在训练数据中过拟合

    具体做法：在损失函数中添加一项有关模型权重向量的的函数，从而使损失增加

    正规化形式：SimpleUpdater，相当于没有正规化，是逻辑回归的默认配置，SquaredL2Updater，基于权重向量的L2正规化，是SVM的默认配置，L1Updater，基于权重向量的L1正规化，会得到一个稀疏的权重向量（不重要的权重值接近0）

2. 决策树

(1) 树的深度和不存度调优：深度越大，得到的模型也复杂，有更好的拟合结果，但是要防止过拟合。不纯度，Gini或者Entropy，两种纯度的方法对性能的影响差异较小

3. 朴素贝叶斯

(1) lamda参数：控制相加式平滑(additive smoothing),解决数据中某个类别和某个特征值的组合没有同时出现的问题 （？question ？）

4. 交叉验证

一部分数据用来训练模型，一部分数据用来评估模型的性能（实际上至少使用50%的数据用于训练）

K-折叠交叉验证

*损失函数*

1、logistic loss -> 逻辑回归模型  2、hinge loss -> SVM模型

## 构建回归模型 ##

* 常见的回归模型

1. 线性模型： 最小二乘损失函数

2. 决策树模型：不纯度度量方法是方差，和最小二乘回归模型的定义方差损失是一样的。但是可以使用较复杂的非线性模型来拟合数据






